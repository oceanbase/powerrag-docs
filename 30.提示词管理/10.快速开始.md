# 快速开始

本文帮助您创建第一个提示词，并在您的应用中使用。

## 获取 API 密钥
1. 使用 PowerRAG 账号登录 PowerRAG Langfuse 控制台。
2. 从页面左下角单击 **设置** > **API 密钥**，创建并获取 API 密钥，包括公钥和私钥。

## 创建提示词
### 使用控制台
使用 Langfuse 控制台创建新提示词或更新现有提示词。

1. 在导航栏选择 **提示词**，单击页面右上角 **+提示词**。
2. 输入提示词参数，例如：
    - 名称：`movie-critic`
    - 提示词文本：`As a {{criticlevel}} movie critic, do you like {{movie}}?`
    - config：`{"model": "gpt-4o"}`
    - 标签：选择** 生产 **标签，创建后将直接推到生产环境。
3. 单击 **创建提示**，完成提示词的创建。
4. 创建后自动进入提示词详情页面，单击左上角 **+New**，可更新提示词，参数配置方法与创建时相同。修改完成后，单击 **保存新的提示版本**。
5. 若未选择“生产”标签，需要手动推到生产环境。在提示词详情页面左侧版本列表，单击版本后的![](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/powerrag/langfuse/icon1.png)图标，选择 **生产**，单击 **保存**，即可推到生产环境。

### 使用 Python SDK
1. 安装 SDK。

```python
pip install langfuse
```

2. 配置环境变量。 在项目根目录下创建 .env 文件，并添加以下配置项：

```python
LANGFUSE_SECRET_KEY = "sk-lf-..."
LANGFUSE_PUBLIC_KEY = "pk-lf-..."
LANGFUSE_HOST = "https://xxx"
```

3. 使用 Python SDK 创建新提示词或更新现有提示词。

```python
# 创建文本提示词
langfuse.create_prompt(
    name="movie-critic",
    type="text",
    prompt="As a {{criticlevel}} movie critic, do you like {{movie}}?",
    labels=["production"],  # 直接推到生产环境
    config={
        "model": "gpt-4o",
        "temperature": 0.7,
        "supported_languages": ["en", "fr"],
    },  # （可选）添加配置（例如模型参数或模型工具）或标签
)
 
# 创建聊天提示词
langfuse.create_prompt(
    name="movie-critic-chat",
    type="chat",
    prompt=[
      { "role": "system", "content": "You are an {{criticlevel}} movie critic" },
      { "role": "user", "content": "Do you like {{movie}}?" },
    ],
    labels=["production"],  # 直接推到生产环境
    config={
        "model": "gpt-4o",
        "temperature": 0.7,
        "supported_languages": ["en", "fr"],
    },  # （可选）添加配置（例如模型参数或模型工具）或标签
)
```

<main id="notice" type='notice'>
    <h4>注意</h4>
    <p>如果您已经创建过名称相同的提示词，则该提示词将作为新版本添加。</p>
</main>

### 使用 JS/TS SDK
1. 安装 SDK

```python
npm i @langfuse/client
```

2. 配置环境变量或构造函数参数
+ 环境变量

 	在项目根目录下创建 .env 文件，并添加以下配置项：

```python
LANGFUSE_SECRET_KEY = "sk-lf-...";
LANGFUSE_PUBLIC_KEY = "pk-lf-...";
LANGFUSE_BASE_URL = "xxx";
```

配置环境变量：

```python
import { LangfuseClient } from "@langfuse/client";
 
const langfuse = new LangfuseClient();
```

+ 构造函数参数

```python
import { LangfuseClient } from "@langfuse/client";
 
const langfuse = new LangfuseClient({
  secretKey: "sk-lf-...",
  publicKey: "pk-lf-...",
  baseUrl: "xxx",
});
```

3. 使用 JS/TS SDK 创建新提示或更新现有提示。

```python
// 创建文本提示词
await langfuse.prompt.create({
  name: "movie-critic",
  type: "text",
  prompt: "As a {{criticlevel}} critic, do you like {{movie}}?",
  labels: ["production"], // 直接推到生产环境
  config: {
    model: "gpt-4o",
    temperature: 0.7,
    supported_languages: ["en", "fr"],
  }, // （可选）添加配置（例如模型参数或模型工具）或标签
});
 
// 创建聊天提示词
await langfuse.prompt.create({
  name: "movie-critic-chat",
  type: "chat",
  prompt: [
    { role: "system", content: "You are an {{criticlevel}} movie critic" },
    { role: "user", content: "Do you like {{movie}}?" },
  ],
  labels: ["production"], // 直接推到生产环境
  config: {
    model: "gpt-4o",
    temperature: 0.7,
    supported_languages: ["en", "fr"],
  }, // （可选）添加配置（例如模型参数或模型工具）或标签
});
```

<main id="notice" type='explain'>
    <h4>说明</h4>
    <p>如果您已经创建过名称相同的提示词，则该提示词将作为新版本添加。</p>
</main>

## 使用提示词
在运行时，您可以从 Langfuse 获取最新的生产版本。关于版本和标签管理，请参见 [版本控制](../30.提示词管理/30.核心功能/00.版本控制.md)。

### 使用 Python SDK
```python
from langfuse import get_client

# 初始化客户端。
langfuse = get_client()
```

#### 文本提示词
```python
# 获取文本提示词的当前生产版本。
prompt = langfuse.get_prompt("movie-critic")
 
# 将变量插入提示词模板。
compiled_prompt = prompt.compile(criticlevel="expert", movie="Dune 2")
# -> "As an expert movie critic, do you like Dune 2?"
```

#### 聊天提示词
```python
# 获取聊天提示词的当前生产版本。
chat_prompt = langfuse.get_prompt("movie-critic-chat", type="chat") # type 为提示词类型（默认类型为文本 'text'）。
 
# 将变量插入聊天提示词模板。
compiled_chat_prompt = chat_prompt.compile(criticlevel="expert", movie="Dune 2")
# -> [{"role": "system", "content": "You are an expert movie critic"}, {"role": "user", "content": "Do you like Dune 2?"}]
```

#### 可选参数
```python
# 获取特定版本。
prompt = langfuse.get_prompt("movie-critic", version=1)
 
# 获取特定标签。
prompt = langfuse.get_prompt("movie-critic", label="staging")
 
# 获取最新提示词版本。latest 标签由 Langfuse 自动维护。
prompt = langfuse.get_prompt("movie-critic", label="latest")
```

#### 属性
```python
# 原始提示词，包括 {{variables}}。对于聊天提示词，是聊天消息列表。
prompt.prompt
 
# 配置对象
prompt.config
```

### 使用 JS/TS SDK
```python
import { LangfuseClient } from "@langfuse/client";
 
// 初始化客户端。
const langfuse = new LangfuseClient();
```

#### 文本提示词
```python
// 获取文本提示词的当前生产版本。
const prompt = await langfuse.prompt.get("movie-critic");
 
// 将变量插入提示词模板。
const compiledPrompt = prompt.compile({
  criticlevel: "expert",
  movie: "Dune 2",
});
// -> "As an expert movie critic, do you like Dune 2?"
```

#### 聊天提示词
```python
// 获取聊天提示词的当前生产版本。
const chatPrompt = await langfuse.prompt.get("movie-critic-chat", {
  type: "chat",
}); // type 为提示词类型（默认类型为文本 'text'）。
 
// 将变量插入聊天提示词模板。
const compiledChatPrompt = chatPrompt.compile({
  criticlevel: "expert",
  movie: "Dune 2",
});
// -> [{"role": "system", "content": "You are an expert movie critic"}, {"role": "user", "content": "Do you like Dune 2?"}]
```

#### 可选参数
```python
// 获取特定版本。
const prompt = await langfuse.prompt.get("movie-critic", {
  version: 1
});
 
// 获取特定标签。
const prompt = await langfuse.prompt.get("movie-critic", {
  label: "staging",
});
 
// 获取最新提示词版本。latest 标签由 Langfuse 自动维护。
const prompt = await langfuse.prompt.get("movie-critic", {
  label: "latest",
});
```

#### 属性
```python
// 原始提示词，包括 {{variables}}。对于聊天提示词，是聊天消息列表。
prompt.prompt;
 
// 配置对象
prompt.config;
```

## 可选：连接 Langfuse 跟踪（Tracing）
您可以将提示词连接到使用该提示词的 LLM `generation` span。此链接可让您直接在 Langfuse 控制台按提示词版本和名称跟踪指标，并查看哪个提示词表现最佳。

### 使用 Python SDK
```python
from langfuse import get_client

# 初始化客户端
langfuse = get_client()
```

#### 装饰器（Decorator）
```python
from langfuse import observe, get_client
 
langfuse = get_client()
 
@observe(as_type="generation")
def nested_generation():
    prompt = langfuse.get_prompt("movie-critic")
 
    langfuse.update_current_generation(
        prompt=prompt,
    )
 
@observe()
def main():
  nested_generation()
 
main()
```

#### 上下文管理器
```python
from langfuse import get_client
 
langfuse = get_client()
 
prompt = langfuse.get_prompt("movie-critic")
 
with langfuse.start_as_current_generation(
    name="movie-generation",
    model="gpt-4o",
    prompt=prompt
) as generation:
    # 在此调用 LLM
    generation.update(output="LLM response")
```

### 使用 JS/TS SDK
#### 手动观测
```python
import { LangfuseClient } from "@langfuse/client";
import { startObservation } from "@langfuse/tracing";
 
const prompt = new LangfuseClient().prompt.get("my-prompt");
 
startObservation(
  "llm",
  {
    prompt,
  },
  { asType: "generation" },
);
```

#### 上下文管理器
```python
import { LangfuseClient } from "@langfuse/client";
import { updateActiveObservation } from "@langfuse/tracing";
 
const langfuse = new LangfuseClient();
 
startActiveObservation(
  "llm",
  async (generation) => {
    const prompt = langfuse.prompt.get("my-prompt");
    generation.update({ prompt });
  },
  { asType: "generation" },
);
```

#### 观测包装器（wrapper）
```python
import { LangfuseClient } from "@langfuse/client";
import { observe } from "@langfuse/tracing";
 
const langfuse = new LangfuseClient();
 
const callLLM = async (input: string) => {
  const prompt = langfuse.prompt.get("my-prompt");
 
  updateActiveObservation({ prompt }, { asType: "generation" });
 
  return await invokeLLM(input);
};
 
export const observedCallLLM = observe(callLLM);
```



