# Experiments overview

Experiments allow you to systematically test your LLM application using a dataset, enabling you to evaluate and compare its performance. 

Each experiment is based on a [Dataset](10.Datasets.md) containing inputs and, optionally, expected outputs. This Dataset can be either local or hosted on Langfuse. For each input, the experiment runs a task functionâ€”this could be your LLM application when using [Experiments via SDK](20.Experiments%20via%20SDK.md), or a prompt sent to a model when using [Experiments via UI](30.Experiments%20via%20UI.md). 

The results can be assessed and scored using various evaluation methods.

## Running experiments

The matrix below shows the different experiment configurations based on where your data is hosted and where the experiment execution takes place:

|  | **Langfuse execution** | **Local/CI execution** |
| --- | --- | --- |
| Langfuse dataset | [Experiments via UI](30.Experiments%20via%20UI.md) | [Experiments via SDK](20.Experiments%20via%20SDK.md) |
| Local dataset | Not supported | [Experiments via SDK](20.Experiments%20via%20SDK.md) |

