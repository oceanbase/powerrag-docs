# 概述

PowerRAG 构建了完善的可观测性（Observability）能力，为大模型（LLM）应用提供端到端的调用链追踪（Tracing）与性能分析。通过可观测性功能，您可以全面了解模型推理的全过程，包括输入、输出、工具调用、重试过程、延迟情况以及每次调用的成本。

## 为什么需要调用链追踪（Tracing）？
在复杂的多模型、多 Agent 系统中，模型的行为往往难以预测。通过调用链追踪，您可以获得系统级的透明度与可控性，从而：

+ 加速开发与调试  通过可视化的错误分析（例如：异常响应、低效提示词、无效重试等），快速理解模型或智能体在运行中的表现，提升迭代效率。
+ 跟踪调用成本  精确记录每次模型调用的 Token 消耗与成本，为成本优化和资源规划提供数据支撑。
+ 降低应用延迟  通过分析调用链的各个阶段（模型响应、API 调用、外部工具交互），识别性能瓶颈并减少总体延迟。
+ 为模型评估奠定基础  调用链数据可作为后续评估体系（如效果评分、质量对比、A/B 测试）的基础数据来源。
+ 节省支持与运维时间  在客户支持或问题排查场景中，可通过调用链快速重现问题，减少人工定位与修复时间。

## 为什么选择 PowerRAG 的可观测能力？
结合 OceanBase 在数据安全与高可用方面的优势，PowerRAG 为企业级 AI 应用提供更稳定、可扩展的可观测方案。

+ 多模态支持：除文本外，PowerRAG 还支持对图像、音频、视频等多模态输入的追踪与分析，帮助用户全面了解复杂交互场景。
+ 多模型兼容：兼容主流模型服务商（如 OpenAI、Anthropic、Claude、Qwen、InternLM 等），可跨模型追踪调用性能与成本。
+ 框架无关性：支持与 LangChain、LlamaIndex、OpenAI SDK 等常用框架集成，也可与 PowerRAG 的工作流编排功能无缝衔接。
+ 多语言支持：支持 Python、JavaScript 等多种语言 SDK，便于在不同技术栈下统一实现追踪与监控。

