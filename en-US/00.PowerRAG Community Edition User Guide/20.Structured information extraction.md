# Structured information extraction

This topic describes how to use structured information extraction in PowerRAG Community Edition.

## Background information

Structured information extraction is the capability to transform unstructured text into standardized data structures. It can identify key entities, attributes, and relationships in documents and output results in machine-readable formats (such as JSON), enabling automated processing and analysis of content that previously required manual reading and retrieval.

In PowerRAG Community Edition, structured information extraction is implemented based on LangExtract capabilities. Through this feature, users can automatically extract key information when importing documents and use these structured results as high-precision retrieval conditions in subsequent queries, filtering, or question-answering processes.

### Use cases

Structured information extraction is suitable for scenarios that require rapid extraction, indexing, and analysis of information from large volumes of documents, such as:

* **Legal and compliance**: Automatically identify key information such as contract numbers, signatories, clauses, amounts, and legal citations.
* **Finance and risk control**: Extract fields such as indicators, transaction records, and credit information from reports for monitoring and modeling.
* **Government and corporate archives**: Transform policy documents, announcements, or meeting minutes into structured records for subsequent retrieval.
* **Content management and knowledge retrieval**: Filter documents by metadata in large-scale knowledge bases, supporting "tag-based" question-answering.

Through structured information extraction, users can quickly build domain-specific information extraction templates and continuously improve the extraction accuracy and stability of models through prompt optimization and feedback mechanisms.

## Procedure

This topic uses structured information extraction from legal documents as an example to introduce the complete workflow from configuring an agent to viewing final results.

### Step 1: Create and configure an agent

1. In the PowerRAG Community Edition console, select the **Agent** module.
2. In the upper right corner of the page, select **Create Agent** > **Create from Template**, and in the template list, select **Ingestion Pipeline** > **Orchestrate Complex Ingestion Pipeline**.
3. In the generated workflow, find the **Generate Metadata** node and click to enter the configuration panel.
4. Complete the following configuration.

    * **flow.extractionType**: Set to `flow.extractionType.langextract`.
    * **Result Destination**: Select **Metadata**.
    * **flow.promptDescription**: Write a description of the structured information extraction requirements. You can refer to the following example.

      ```plain
      Extract the following information from the provided legal text:
      - Contract number (contract_number)
      - Signing date (sign_date)
      - Contract parties (parties)
      - Contract amount (amount)
      - Key terms (key_terms)
      - Legal references (legal_references)
      - Case number (case_number)
      - Litigants (litigants)
      - Case type (case_type)
      - Judgment result (judgment)

      Requirements:
      - extraction_text must be original text fragments from the input text, not rewritten or abbreviated;
      - Each entity must not overlap with other entities;
      - Extract in the order they appear in the text;
      - Provide attributes field for each extraction item, for example:
        * parties: {"role": "Party A" or "Party B" or "Plaintiff" or "Defendant"}
        * key_terms: {"type": "Breach of Contract" or "Dispute Resolution", etc.}
        * legal_references: {"law_type": "Law" or "Administrative Regulation", etc.}
      ```

    * **Examples**: Provide example output. You can refer to the following example.

      ```json
      {
        "extractions": [
          {
            "extraction_class": "contract_number",
            "extraction_text": "HT2024001"
          },
          {
            "extraction_class": "sign_date",
            "extraction_text": "2024-03-15"
          },
          {
            "attributes": {
              "role": "Party A"
            },
            "extraction_class": "parties",
            "extraction_text": "Beijing Technology Co., Ltd."
          },
          {
            "attributes": {
              "role": "Party B"
            },
            "extraction_class": "parties",
            "extraction_text": "Shanghai Software Co., Ltd."
          },
          {
            "extraction_class": "amount",
            "extraction_text": "RMB 1.2 million"
          },
          {
            "attributes": {
              "law_type": "Law"
            },
            "extraction_class": "legal_references",
            "extraction_text": "Article 39 of the Contract Law"
          },
          {
            "attributes": {
              "type": "Breach of Contract"
            },
            "extraction_class": "key_terms",
            "extraction_text": "If Party B delays delivery for more than 30 days, it shall pay 10% of the total contract amount as liquidated damages"
          },
          {
            "attributes": {
              "type": "Dispute Resolution"
            },
            "extraction_class": "key_terms",
            "extraction_text": "Submit to Arbitration Commission for arbitration"
          }
        ],
        "text": "The Software Development Service Contract numbered HT2024001 was signed on March 15, 2024. Party A: Beijing Technology Co., Ltd., Party B: Shanghai Software Co., Ltd. The total contract amount is RMB 1.2 million. According to Article 39 of the Contract Law, the parties agree: If Party B delays delivery for more than 30 days, it shall pay 10% of the total contract amount as liquidated damages. Dispute resolution method: Submit to Arbitration Commission for arbitration."
      }
      ```

5. Configure the workflow as needed, then save the agent. For specific workflow orchestration operations, please refer to the [RAGFlow documentation](https://ragflow.io/docs/dev/agent_introduction).

### Step 2: Create and configure a knowledge base

1. In the **Knowledge Base** module, click **Create Knowledge Base**.
2. In the popup, enter the knowledge base name, select an embedding model, then under **Ingestion pipeline**, select **Select pipeline**, choose the Pipeline you just created from the dropdown, and save.
3. Configure the knowledge base as needed. For specific operations, please refer to the [RAGFlow Datasets documentation](https://ragflow.io/docs/dev/configure_knowledge_base).
4. Upload the document files to be extracted and complete parsing.

### Step 3: Create and configure a chat

1. Create a new session in the **Chat** module.
2. In the chat settings of the session, configure as follows:
    1. Knowledge Base: Select the knowledge base created in the previous step.
    2. Metadata: Set to **Automatic**.
    3. Other parameters can be configured as needed according to the [RAGFlow Chat documentation](https://ragflow.io/docs/dev/category/chat).

### Step 4: View extraction results

After completing the configuration, you can verify extraction results through natural language queries on the current page. For example, enter the query: "Find technical consulting service contracts with contract amounts between 800,000 and 900,000 yuan."

* When metadata is enabled, the system can directly return matching results based on the extracted structured information.
* If metadata is disabled, the query will not return results because structured fields cannot be accessed.

## API usage

PowerRAG also provides corresponding APIs, allowing users to extract structured information from text, URLs, or multiple documents through API calls. These interfaces can be integrated with other systems, supporting automated task processing and batch data extraction. This section describes how to submit structured extraction tasks through APIs and how to query task status.

### Authentication

All interfaces require **Bearer Token** authentication. The token is obtained through the API Key provided by RAGFlow.

```plain
Authorization: Bearer ragflow-<your-api-key>
```

### API list

#### 1. Submit structured extraction task

* **Endpoint**: `POST /api/v1/powerrag/struct_extract/submit`
* **Authentication**: API Key required
* **Description**: This endpoint is used to submit a structured extraction task, supporting extraction of structured information from text, URLs, or multiple documents. After task submission, a `task_id` is returned, which users can use to query task status and extraction results.

##### Request parameters

###### Required parameters

| **Parameter** | **Type** | **Description** |
| --- | --- | --- |
| `text_or_documents` | string \| array | Text content to be extracted. Supports two formats:<ul><li>**String format**: Directly provide text content or URL (when `fetch_urls=true`).</li><li>**Array format**: Multi-document extraction, each document contains:<ul><li>`text` (string, **required**): Document text content</li><li>`document_id` (string, **optional**): Document ID, auto-generated if not provided</li><li>`additional_context` (string, **optional**): Additional context information for the document</li></ul></li></ul> |
| `prompt_description` | string | Description of the extraction task, specifying what types of information need to be extracted. |
| `examples` | array | Example array, must contain at least one example. Each example contains:<ul><li>`text` (string): Example text</li><li>`extractions` (array): Extraction result array, each extraction item contains:<ul><li>`extraction_class` (string): Extraction category (such as "name", "location", "date", etc.)</li><li>`extraction_text` (string): Extracted text content (must be original text fragments)</li><li>`attributes` (object, **optional**): Attribute information for the extraction item</li></ul></li></ul> |

###### Optional parameters

| **Parameter** | **Type** | **Default** | **Description** |
| --- | --- | --- | --- |
| `fetch_urls` | boolean | false | When `text_or_documents` is a URL, whether to automatically fetch URL content. |
| `max_char_buffer` | integer | 1000 | Character buffer size. |
| `temperature` | float | none | LLM temperature parameter, controls output randomness. Higher values produce more random output. |
| `extraction_passes` | integer | 1 | Number of extraction passes, default is 1. Multiple passes can improve accuracy. |
| `additional_context` | string | none | Global additional context information, provided to the model for reference. |
| `prompt_validation_level` | string | "WARNING" | Prompt validation level, determines how to handle content that does not conform to the prompt format. |
| `prompt_validation_strict` | boolean | false | Whether to strictly validate prompts, default is off. |
| `resolver_params` | object | none | Resolver parameters:<ul><li>`enable_fuzzy_alignment` (boolean): Whether to enable fuzzy alignment</li><li>`fuzzy_alignment_threshold` (float): Fuzzy alignment threshold</li></ul> |
| `model_parameters` | object | none | Model parameters:<ul><li>`max_tokens` (integer): Maximum number of tokens</li></ul> |
| `timeout` | integer | none | Task timeout in seconds. |

##### Request examples

###### Example 1: Parse single text

Extract name, location, and date information from a single text:

```bash
curl -X POST "http://xxx.xxx.xxx.xxx:xxxx/api/v1/powerrag/struct_extract/submit" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ragflow-A2MzxxxxxxxxMDAxNj" \
  -d '{
    "text_or_documents": "John attended a conference in New York on January 1, 2024. Sarah will visit Paris on March 15, 2024.",
    "prompt_description": "Extract names, locations, and dates from the text.",
    "examples": [
      {
        "text": "John attended a conference in New York on January 1, 2024.",
        "extractions": [
          {
            "extraction_class": "name",
            "extraction_text": "John"
          },
          {
            "extraction_class": "location",
            "extraction_text": "New York"
          },
          {
            "extraction_class": "date",
            "extraction_text": "January 1, 2024"
          }
        ]
      }
    ]
  }'
```

###### Example 2: Extract from URL

Fetch content from a specified URL and extract information:

```bash
curl -X POST "http://xxx.xxx.xxx.xxx:xxxx/api/v1/powerrag/struct_extract/submit" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ragflow-A2MzxxxxxxxxMDAxNj" \
  -d '{
    "text_or_documents": "http://xxx.xxx.xxx.xxx:8888/powerrag/wget-log",
    "prompt_description": "Extract names, locations, and dates from the text.",
    "examples": [
      {
        "text": "John attended a conference in New York on January 1, 2024.",
        "extractions": [
          {
            "extraction_class": "name",
            "extraction_text": "John"
          },
          {
            "extraction_class": "location",
            "extraction_text": "New York"
          },
          {
            "extraction_class": "date",
            "extraction_text": "January 1, 2024"
          }
        ]
      }
    ],
    "fetch_urls": true
  }'
```

###### Example 3: Multi-document extraction

Extract patient names, disease names, and medication information from multiple clinical medical records, and use the `attributes` field for classification:

```bash
curl -X POST "http://xxx.xxx.xxx.xxx:xxxx/api/v1/powerrag/struct_extract/submit" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ragflow-A2MzxxxxxxxxMDAxNj" \
  -d '{
    "text_or_documents": [
      {
        "text": "Patient Han Li, male, 68 years old, visited for recurrent dizziness. History of cerebral infarction, currently taking clopidogrel and rosuvastatin.",
        "document_id": "doc1"
      },
      {
        "text": "Patient Nangong Wan, female, 54 years old, diagnosed with breast cancer and receiving chemotherapy, currently taking letrozole and denosumab.",
        "document_id": "doc2"
      }
    ],
    "prompt_description": "Extract patient names, disease names, and medication information from clinical medical records. Provide attributes field for each extraction item.",
    "examples": [
      {
        "text": "Patient Wang Lin, type 2 diabetes patient, long-term oral metformin.",
        "extractions": [
          {
            "extraction_class": "name",
            "extraction_text": "Wang Lin"
          },
          {
            "attributes": {"category": "diagnosis"},
            "extraction_class": "disease",
            "extraction_text": "Type 2 diabetes"
          },
          {
            "attributes": {"category": "treatment"},
            "extraction_class": "medication",
            "extraction_text": "Metformin"
          }
        ]
      }
    ]
  }'
```

##### Response format

###### Success response (200)

```json
{
    "code": 0,
    "data": {
        "task_id": "262134e2-6b10-4c6b-972d-c4cb66b21b16"
    },
    "message": "Task submitted successfully"
}
```

###### Error responses

* **400**: Parameter error
* **503**: Server busy
* **500**: Internal server error

#### 2. Query task status

* **Endpoint**: `GET /api/v1/powerrag/struct_extract/status/<task_id>`
* **Authentication**: API Key required
* **Description**: Query the status and results of a submitted structured extraction task.

##### Request parameters

| **Parameter** | **Type** | **Description** |
| --- | --- | --- |
| `task_id` | string | Task ID returned after task submission |

##### Request example

```bash
curl -X GET "http://xxx.xxx.xxx.xxx:xxxx/api/v1/powerrag/struct_extract/status/262134e2-6b10-4c6b-972d-c4cb66b21b16" \
  -H "Authorization: Bearer ragflow-A2MzxxxxxxxxMDAxNj"
```

##### Response format

###### Success response (200)

```json
{
    "code": 0,
    "data": {
        "task_id": "262134e2-6b10-4c6b-972d-c4cb66b21b16",
        "status": "success",
        "created_at": "2025-01-01T00:00:00",
        "updated_at": "2025-01-01T00:00:00",
        "result": {
            "extractions": [
                {
                    "extraction_class": "name",
                    "extraction_text": "John",
                    "document_id": "doc1"
                },
                {
                    "extraction_class": "location",
                    "extraction_text": "New York",
                    "document_id": "doc1"
                }
            ]
        }
    },
    "message": "success"
}
```

Response field descriptions:

| **Field** | **Type** | **Description** |
| --- | --- | --- |
| `task_id` | string | Task ID, unique identifier returned after user submits a task |
| `status` | string | Current task status, including:<ul><li>`pending`: Task submitted, waiting for processing</li><li>`processing`: Task is being processed</li><li>`success`: Task processed successfully, results can be obtained through the `result` field</li><li>`failed`: Task processing failed, error information returned through the `error` field</li><li>`not_found`: Task not found, returns 404 error</li></ul> |
| `created_at` | string | Task creation time, ISO 8601 format |
| `updated_at` | string | Task update time, ISO 8601 format |
| `result` | object | Returned when task succeeds, contains extracted structured results |
| `extractions` | array | Extraction result array, contains information for each extraction item:<ul><li>`extraction_class`: Extraction category</li><li>`extraction_text`: Extracted text content</li><li>`document_id`: Document ID (for multi-document extraction)</li><li>`attributes`: Extraction item attributes (if provided)</li></ul> |
| `error` | string | Error information, returned when task fails |

###### Error responses

* **404**: Task not found
* **500**: Server processing failed

